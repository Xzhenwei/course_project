In this project, we completed the framework followed by instructions. We first completed the MLPActorCritic step function which provides sampling a policy from the policy neural network approximation, a sampled action from the policy as well as estimation of the value. Then we completed the policy update function and value update function followed the instructions of task description. Then we update the policy neural networks at the end of each epoch based on optimizers and architectures in the code. Finally, we implement the function to get the action: get_action() function which returns an action. Moreover, we followed the instruction that in each batch of updates, the distribution of the advantages was normalized so they have the same distribution. By changing different values of steps and epochs, we finalized our parameters by taking the highest return.